{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon #3\n",
    "\n",
    "Written by Eleanor Quint\n",
    "\n",
    "Topics: \n",
    "- Saving and loading TensorFlow models\n",
    "- Running TensorFlow-based Python programs on Crane\n",
    "- Overfitting, regularization, and early stopping\n",
    "\n",
    "This is all setup in a IPython notebook so you can run any code you want to experiment with. Feel free to edit any cell, or add some to run your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll start with our library imports...\n",
    "from __future__ import print_function\n",
    "\n",
    "import os  # to work with file paths\n",
    "\n",
    "import tensorflow as tf         # to specify and run computation graphs\n",
    "import numpy as np              # for numerical operations taking place outside of the TF graph\n",
    "import matplotlib.pyplot as plt # to draw plots\n",
    "\n",
    "mnist_dir = '/work/cse496dl/shared/hackathon/03/mnist/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract our dataset, MNIST\n",
    "train_images = np.load(mnist_dir + 'mnist_train_images.npy')\n",
    "train_labels = np.load(mnist_dir + 'mnist_train_labels.npy')\n",
    "test_images = np.load(mnist_dir + 'mnist_test_images.npy')\n",
    "test_labels = np.load(mnist_dir + 'mnist_test_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0916 16:14:16.256666 47719223038080 deprecation.py:323] From <ipython-input-3-f02708e243a6>:7: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0916 16:14:16.269116 47719223038080 deprecation.py:506] From /util/opt/anaconda/deployed-conda-envs/packages/tensorflow/envs/tensorflow-1.14.0-py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# Clear the graph\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='data_placeholder')\n",
    "# use a single name scope for the model\n",
    "with tf.name_scope('linear_model') as scope:\n",
    "    hidden = tf.layers.dense(x, 200, activation=tf.nn.relu, name='hidden_layer')\n",
    "    output = tf.layers.dense(hidden, 10, name='output_layer')\n",
    "    \n",
    "    # Below is \"identity trick\"\n",
    "    # tf.identity seems useless, but gives name to output so we can easily find it\n",
    "    tf.identity(output, name='model_output')\n",
    "\n",
    "# This is an easy way to track how much training the model has been through\n",
    "# Acts as counter that updates once every time we track errors back\n",
    "global_step_tensor = tf.get_variable('global_step', trainable=False, shape=[], initializer=tf.zeros_initializer)\n",
    "# Declares tensorflow function for saving the model\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the preceding code is copied (with small modifications) from hackathon 2. We'll use it to illustrate saving and loading. Some notable modifications are the declaration of the 'global_step_tensor', the addition of the 'model_output' identity operation (which adds to the graph, even though we don't save the handle), and the addition of 'saver'.\n",
    "\n",
    "### Saving and Loading TensorFlow Models\n",
    "\n",
    "To save a model with initialized variables, we use the [save method](https://www.tensorflow.org/api_docs/python/tf/train/Saver#save) of an instance of [tf.train.Saver](https://www.tensorflow.org/api_docs/python/tf/train/Saver). Notice that this returns the checkpoint path prefix which may be passed directly to `Saver`'s load functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.69763786  0.05265693 -0.10597296 -0.04521304 -0.19031602  0.12239566\n",
      "  -0.1009571  -0.28437117 -0.44811592  0.52677745]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "save_directory = './hackathon3_logs'\n",
    "with tf.Session() as session:\n",
    "    # Session keeps track of value of variables we are training\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Run model forward once to get example\n",
    "    # We use np.expand_dims as train_images is (50000,784) and train_images[42] is 784\n",
    "    # As we are passing only one example, expand_dims turns dimension of train_images[42] to (1,784)\n",
    "    img, class_vec = session.run([x, output], {x: np.expand_dims(train_images[42], axis=0)})\n",
    "    print(class_vec) # Untrained output data\n",
    "    imgplot = plt.imshow(img.reshape((28,28)))\n",
    "    \n",
    "    # the next lines save the graph and variables in save_directory \n",
    "    # as \"mnist_inference.ckpt.meta\" and \"mnist_inference.ckpt\"\n",
    "    # Passing in global_step_tensor also keeps track of the counter therefore\n",
    "    path_prefix = saver.save(session, os.path.join(save_directory, \"mnist_classification\"), global_step=global_step_tensor)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll clear the graph and try to run a datum through the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./hackathon3_logs/mnist_classification-0\n"
     ]
    }
   ],
   "source": [
    "# Clear the graph\n",
    "tf.reset_default_graph()\n",
    "# Declare new session\n",
    "session = tf.Session()\n",
    "# Grab graph for this session\n",
    "graph = session.graph\n",
    "\n",
    "# the following line fails because the placeholder tensor isn't in the graph anymore (as we reset)\n",
    "# session.run(output, {x: np.expand_dims(train_images[42], axis=0)})\n",
    "\n",
    "print(path_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the last line is uncommented, we get what is essentially an \"operation not found\" error. Now let's load the graph structure we saved before with [tf.train.import_meta_graph](https://www.tensorflow.org/api_docs/python/tf/train/import_meta_graph) and then use [Saver.restore](https://www.tensorflow.org/api_docs/python/tf/train/Saver#restore) to load and initialize the variable values. We can get handles to the in-graph `Tensor`s with [Graph.get_tensor_by_name](https://www.tensorflow.org/api_docs/python/tf/Graph#get_tensor_by_name) and passing the name of the tensor (which is differentiated from the name of the operation by the \":0\", which denotes the 0th tensor output of the op). We can then run the operations as normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 16:14:18.118891 47719223038080 deprecation.py:323] From /util/opt/anaconda/deployed-conda-envs/packages/tensorflow/envs/tensorflow-1.14.0-py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Operation 'data_placeholder' type=Placeholder>, <tf.Operation 'hidden_layer/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'hidden_layer/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'hidden_layer/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'hidden_layer/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'hidden_layer/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'hidden_layer/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'hidden_layer/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'hidden_layer/kernel' type=VariableV2>, <tf.Operation 'hidden_layer/kernel/Assign' type=Assign>, <tf.Operation 'hidden_layer/kernel/read' type=Identity>, <tf.Operation 'hidden_layer/bias/Initializer/zeros' type=Const>, <tf.Operation 'hidden_layer/bias' type=VariableV2>, <tf.Operation 'hidden_layer/bias/Assign' type=Assign>, <tf.Operation 'hidden_layer/bias/read' type=Identity>, <tf.Operation 'linear_model/hidden_layer/MatMul' type=MatMul>, <tf.Operation 'linear_model/hidden_layer/BiasAdd' type=BiasAdd>, <tf.Operation 'linear_model/hidden_layer/Relu' type=Relu>, <tf.Operation 'output_layer/kernel/Initializer/random_uniform/shape' type=Const>, <tf.Operation 'output_layer/kernel/Initializer/random_uniform/min' type=Const>, <tf.Operation 'output_layer/kernel/Initializer/random_uniform/max' type=Const>, <tf.Operation 'output_layer/kernel/Initializer/random_uniform/RandomUniform' type=RandomUniform>, <tf.Operation 'output_layer/kernel/Initializer/random_uniform/sub' type=Sub>, <tf.Operation 'output_layer/kernel/Initializer/random_uniform/mul' type=Mul>, <tf.Operation 'output_layer/kernel/Initializer/random_uniform' type=Add>, <tf.Operation 'output_layer/kernel' type=VariableV2>, <tf.Operation 'output_layer/kernel/Assign' type=Assign>, <tf.Operation 'output_layer/kernel/read' type=Identity>, <tf.Operation 'output_layer/bias/Initializer/zeros' type=Const>, <tf.Operation 'output_layer/bias' type=VariableV2>, <tf.Operation 'output_layer/bias/Assign' type=Assign>, <tf.Operation 'output_layer/bias/read' type=Identity>, <tf.Operation 'linear_model/output_layer/MatMul' type=MatMul>, <tf.Operation 'linear_model/output_layer/BiasAdd' type=BiasAdd>, <tf.Operation 'linear_model/model_output' type=Identity>, <tf.Operation 'global_step/Initializer/zeros' type=Const>, <tf.Operation 'global_step' type=VariableV2>, <tf.Operation 'global_step/Assign' type=Assign>, <tf.Operation 'global_step/read' type=Identity>, <tf.Operation 'save/filename/input' type=Const>, <tf.Operation 'save/filename' type=PlaceholderWithDefault>, <tf.Operation 'save/Const' type=PlaceholderWithDefault>, <tf.Operation 'save/SaveV2/tensor_names' type=Const>, <tf.Operation 'save/SaveV2/shape_and_slices' type=Const>, <tf.Operation 'save/SaveV2' type=SaveV2>, <tf.Operation 'save/control_dependency' type=Identity>, <tf.Operation 'save/RestoreV2/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2' type=RestoreV2>, <tf.Operation 'save/Assign' type=Assign>, <tf.Operation 'save/Assign_1' type=Assign>, <tf.Operation 'save/Assign_2' type=Assign>, <tf.Operation 'save/Assign_3' type=Assign>, <tf.Operation 'save/Assign_4' type=Assign>, <tf.Operation 'save/restore_all' type=NoOp>, <tf.Operation 'init' type=NoOp>]\n",
      "[[-0.69763786  0.05265693 -0.10597296 -0.04521304 -0.19031602  0.12239566\n",
      "  -0.1009571  -0.28437117 -0.44811592  0.52677745]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# loading the meta graph re-creates the graph structure in the current session, and restore initializes saved variables\n",
    "saver = tf.train.import_meta_graph(path_prefix + '.meta')\n",
    "# Directory where data file and index file are in is path_prefix\n",
    "saver.restore(session, path_prefix)\n",
    "\n",
    "# get handles to graph Tensors, noticing the use of name scope in retrieving model_output\n",
    "x = graph.get_tensor_by_name('data_placeholder:0')\n",
    "\n",
    "# Uses created name for output we created to grab that tensor\n",
    "output = graph.get_tensor_by_name('linear_model/model_output:0')\n",
    "\n",
    "# Prints out all operations we declared in the graph (just for information purposes)\n",
    "print(graph.get_operations())\n",
    "\n",
    "# Now rerun, exactly the same as before\n",
    "img, class_vec = session.run([x, output], {x: np.expand_dims(train_images[42], axis=0)})\n",
    "\n",
    "# We see, as expected we get the same output we did before\n",
    "print(class_vec)\n",
    "imgplot = plt.imshow(img.reshape((28,28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running TensorFlow-based Python programs on Crane\n",
    "\n",
    "Because these IPython notebooks are run on the Crane login node, we should not attempt to run more than a trivially sized program. This means that we are not allowed to run more than a few training steps of a small model. Larger jobs, like fully optimizing a model, must be submitted to Slurm, the job scheduling manager for the Crane node.\n",
    "\n",
    "We're now going to open a terminal from Jupyter to run the following commands:\n",
    "\"\n",
    "\n",
    "```\n",
    "cd $WORK\n",
    "cp /work/cse496dl/shared/hackathon/03/run_py_496dl.sh $WORK\n",
    "cp /work/cse496dl/shared/hackathon/03/basic.py $WORK\n",
    "```\n",
    "\n",
    "I've distributed a file called, \"run_py_496dl.sh\". It is most of what is needed to submit a Python program with TensorFlow installed and running on GPU. It expects a python file with a main function, and submits the job using `sbatch`:\n",
    "\n",
    "`sbatch ./run_py_496dl.sh basic.py`\n",
    "\n",
    "The way I have it written, it also passes through all arguments that follow the `.py`. Let's submit a job and then go over the details of the submit script. You can check on the status of your pending and running jobs with `squeue -u <USERNAME>`, substituting your Crane username, and you can cancel jobs with `scancel <JOBID>`, substituting the job id displayed by `squeue`. For more details, please visit the [HCC docs](https://hcc-docs.unl.edu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# In piazza she gave us standard run_py_479.sh script\n",
    "\n",
    "# Submitting to cse479_preempt partition allows us to submit unlimited requests, but they may be killed any\n",
    "# time someone submits a job on cse479 and there are no available resources\n",
    "\n",
    "# Submitting to cse479 is only allowed for one submission at a time, but will not be killed and has resource\n",
    "# priority\n",
    "\n",
    "# To check status run saact and it gives status of all running tasks, and canceled ones\n",
    "\n",
    "# Using squeue -u equint shows ques and running tasks (for user named equint)\n",
    "# Using squeue -p cse479 shows ques and running tasks (cse479 partition)\n",
    "\n",
    "# To kill a job copy job ID from queue\n",
    "# Use scancel 2238356 (assuming that number was the job ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overfitting, regularization, and early stopping\n",
    "\n",
    "If we have enough parameters in our model, and little enough data, after a long period of training we begin to experience overfitting. Empirically, this is when the loss value of the data visible to the model in training drops significantly below the loss value of the data set aside for testing. It implies that the model is looking for patterns specific to the training data that won't generalize to future, unseen data. This is a problem.\n",
    "\n",
    "Solutions? Here are some first steps to think about:\n",
    "\n",
    "1. Get more data\n",
    "2. Reduce the number of parameters in the model\n",
    "3. Regularize the weight/bias parameters of the model\n",
    "4. Regularize using dropout\n",
    "5. Early Stopping\n",
    "\n",
    "Let's re-specify the network with regularization from [dropout](https://www.tensorflow.org/api_docs/python/tf/layers/dropout). Other common regularizers can be found in [tf.contrib.layers](https://www.tensorflow.org/api_docs/python/tf/contrib/layers) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 16:14:18.699757 47719223038080 deprecation.py:323] From <ipython-input-7-f51f937b1f18>:7: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Dropout helps the neurons to not depend on each other as much\n",
    "\n",
    "KEEP_PROB = 0.7\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='input_placeholder')\n",
    "with tf.name_scope('linear_model') as scope:\n",
    "    \n",
    "    # as strange as it sounds, using dropout on the input sometimes helps\n",
    "    dropped_input = tf.layers.dropout(x, KEEP_PROB)\n",
    "    hidden = tf.layers.dense(dropped_input,\n",
    "                             400,\n",
    "                             activation=tf.nn.relu,\n",
    "                             name='hidden_layer')\n",
    "    \n",
    "    # After hidden layer drop 30% of output before output\n",
    "    dropped_hidden = tf.layers.dropout(hidden, KEEP_PROB)\n",
    "    output = tf.layers.dense(dropped_hidden,\n",
    "                             10,\n",
    "                             name='output_layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, alternatively, a network using [tf.contrib.layers.l2_regularizer](https://www.tensorflow.org/api_docs/python/tf/contrib/layers/l2_regularizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 16:14:22.280245 47719223038080 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# Puts penalty on growth of the weights\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 784], name='input_placeholder')\n",
    "with tf.name_scope('linear_model') as scope:\n",
    "    hidden = tf.layers.dense(x,\n",
    "                             400,\n",
    "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=0.01),\n",
    "                             bias_regularizer=tf.contrib.layers.l2_regularizer(scale=0.01),\n",
    "                             activation=tf.nn.relu,\n",
    "                             name='hidden_layer')\n",
    "    output = tf.layers.dense(hidden,\n",
    "                             10,\n",
    "                             kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=0.01),\n",
    "                             bias_regularizer=tf.contrib.layers.l2_regularizer(scale=0.01),\n",
    "                             name='output_layer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using any amount of numerical regularization, it is important to add the values to the final loss function that is used in `minimize`, otherwise the regularizers do nothing. Built-in regularizers are automatically added to a list that can be retrieved with [tf.get_collection](https://www.tensorflow.org/api_docs/python/tf/get_collection) which takes a [GraphKey](https://www.tensorflow.org/api_docs/python/tf/GraphKeys) and returns a list of tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'linear_model/hidden_layer/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'linear_model/hidden_layer/bias/Regularizer/l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'linear_model/output_layer/kernel/Regularizer/l2_regularizer:0' shape=() dtype=float32>, <tf.Tensor 'linear_model/output_layer/bias/Regularizer/l2_regularizer:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "# define classification loss WITH regularization loss\n",
    "# In our case, it's L2, but could also commonly be L0, L1, or Linf\n",
    "y = tf.placeholder(tf.float32, [None, 10], name='label')\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=output)\n",
    "\n",
    "# Running this line collects all regularization losses from kernel regularizers\n",
    "regularization_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "print(regularization_losses)\n",
    "# this is the weight of the regularization part of the final loss\n",
    "REG_COEFF = 0.001\n",
    "\n",
    "# this value is what we'll pass to `minimize`\n",
    "# This adds the regularization losses to the standard loss function\n",
    "if regularization_losses:\n",
    "    total_loss = cross_entropy + REG_COEFF * sum(regularization_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the most important tool to combat overfitting is early stopping. This is the practice of saving copies of the parameters periodically and, after you've recognized that over-fitting is occurring (i.e., when the loss on the validation/test data doesn't decrease for a number of epochs), stop training and report the best saved copy of the parameters rather than the overfit version.\n",
    "\n",
    "Whether deciding which set of parameters to use from training or trying to decide which form of regularization will work best by trying different kinds, you can get a better idea of how your regularization decisions will affect true generalization by further splitting the training data into training and validation sets. The validation data is left unused in adjusting model parameters, but is still used in training to make regularization decisions, and this leaves the test data to be the true measure of generalization.\n",
    "\n",
    "You might use a function like the following for the task of splitting your data into two numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Early stopping example not given\n",
    "\n",
    "# The below code may be useful in HW\n",
    "# Used for splitting data into different proportions\n",
    "def split_data(data, proportion):\n",
    "    \"\"\"\n",
    "    Split a numpy array into two parts of `proportion` and `1 - proportion`\n",
    "    \n",
    "    Args:\n",
    "        - data: numpy array, to be split along the first axis\n",
    "        - proportion: a float less than 1\n",
    "    \"\"\"\n",
    "    size = data.shape[0]\n",
    "    split_idx = int(proportion * size)\n",
    "    np.shuffle(data)\n",
    "    return data[:split_idx], data[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hackathon 3 Exercise 1\n",
    "\n",
    "Modify the `basic.py` file to add L2 regularization, split the training data to get a validation set, calculate loss on the validation (similar to test), and add early stopping. Train the model on Crane, submitting the job with `sbatch` and report the train, validation, and test loss values of the best set of parameters, along with the training epoch number they were saved from. (This is very similar to what you need to do for the first homework)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Modify the basic.py file given on Piazza, not just this notebook\n",
    "# However, just submit this notebook, with the four values requested below\n",
    "\n",
    "### 1) MODIFY THE CODE, 2) TRAIN ON CRANE, 3) FILL THESE IN 4) SUBMIT THIS .IPYNB\n",
    "# EPOCH: 14\n",
    "# TRAIN LOSS: 0.045720665766434236\n",
    "# VALIDATION LOSS: 0.07949269613759084\n",
    "# TEST LOSS: 0.10437090009450913"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 1.14 (py36)",
   "language": "python",
   "name": "tensorflow-1.14-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
