{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hackathon #5\n",
    "\n",
    "Topics: \n",
    "- Transfer learning\n",
    "    - Changing the final layers of an existing network\n",
    "    - Stopping gradients and freezing layers\n",
    "- Batch Normalization\n",
    "\n",
    "This is all setup in a IPython notebook so you can run any code you want to experiment with. Feel free to edit any cell, or add cells to run your own code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll start with our library imports...\n",
    "from __future__ import print_function\n",
    "\n",
    "import os  # to work with file paths\n",
    "\n",
    "import tensorflow as tf         # to specify and run computation graphs\n",
    "import numpy as np              # for numerical operations taking place outside of the TF graph\n",
    "import matplotlib.pyplot as plt # to draw plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_dir = '/work/cse479/shared/hackathon/05/cifar/'\n",
    "\n",
    "# load CIFAR-10\n",
    "train_images = np.load(cifar_dir + 'cifar10_train_data.npy')\n",
    "train_images = np.reshape(train_images, [-1, 32, 32, 3]) # `-1` means \"everything not otherwise accounted for\"\n",
    "train_labels = np.load(cifar_dir + 'cifar10_train_labels.npy')\n",
    "\n",
    "test_images = np.load(cifar_dir + 'cifar10_test_data.npy')\n",
    "test_images = np.reshape(test_images, [-1, 32, 32, 3]) # `-1` means \"everything not otherwise accounted for\"\n",
    "test_labels = np.load(cifar_dir + 'cifar10_test_labels.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning\n",
    "\n",
    "Let's imagine you have an image classification task that's doable, but don't have a large enough dataset with which to train a network without overfitting. What to do? The answer is to use the convolutional stack of a powerful, existing network that you (or Google) has trained on a broad task like classifying [ImageNet](http://www.image-net.org/) ([Wikipedia](https://en.wikipedia.org/wiki/ImageNet)) and only train a few dense layers on top of it for classification. You get the benefit of good feature extraction without the danger of overfitting such a large network on your small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pull out classes 0 and 2 (airplanes and birds respectively)\n",
    "train_idxs = np.union1d(np.where(train_labels == 0), np.where(train_labels == 2))\n",
    "test_idxs = np.union1d(np.where(test_labels == 0), np.where(test_labels == 2))\n",
    "\n",
    "# the subsets we'll be working with\n",
    "# and handle an off by one error I haven't been able to diagnose\n",
    "subset_train_data = train_images[train_idxs][1:]\n",
    "subset_train_labels = train_labels[train_idxs][1:]\n",
    "subset_test_data = test_images[test_idxs][1:]\n",
    "subset_test_labels = test_labels[test_idxs][1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load a model that's been trained on a similar classification task (the other part of CIFAR-10), and see how it performs. The first thing we have to do is find the tensors we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0930 16:39:50.333127 47074515312768 deprecation.py:323] From /util/opt/anaconda/deployed-conda-envs/packages/tensorflow/envs/tensorflow-1.14.0-py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Operation 'input_placeholder' type=Placeholder>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Initializer/truncated_normal/shape' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Initializer/truncated_normal/mean' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Initializer/truncated_normal/stddev' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Initializer/truncated_normal/TruncatedNormal' type=TruncatedNormal>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Initializer/truncated_normal/mul' type=Mul>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Initializer/truncated_normal' type=Add>, <tf.Operation 'conv_net_2d/conv_2d_0/w' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_0/w/read' type=Identity>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Regularizer/l2_regularizer/scale' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Regularizer/l2_regularizer/L2Loss' type=L2Loss>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Regularizer/l2_regularizer' type=Mul>, <tf.Operation 'conv_net_2d_1/conv_2d_0/convolution/dilation_rate' type=Const>, <tf.Operation 'conv_net_2d_1/conv_2d_0/convolution' type=Conv2D>, <tf.Operation 'conv_net_2d/conv_2d_0/b/Initializer/zeros' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_0/b' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_0/b/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_0/b/read' type=Identity>, <tf.Operation 'conv_net_2d_1/conv_2d_0/BiasAdd' type=BiasAdd>, <tf.Operation 'conv_net_2d_1/Relu' type=Relu>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Initializer/truncated_normal/shape' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Initializer/truncated_normal/mean' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Initializer/truncated_normal/stddev' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Initializer/truncated_normal/TruncatedNormal' type=TruncatedNormal>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Initializer/truncated_normal/mul' type=Mul>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Initializer/truncated_normal' type=Add>, <tf.Operation 'conv_net_2d/conv_2d_1/w' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_1/w/read' type=Identity>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Regularizer/l2_regularizer/scale' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Regularizer/l2_regularizer/L2Loss' type=L2Loss>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Regularizer/l2_regularizer' type=Mul>, <tf.Operation 'conv_net_2d_1/conv_2d_1/convolution/dilation_rate' type=Const>, <tf.Operation 'conv_net_2d_1/conv_2d_1/convolution' type=Conv2D>, <tf.Operation 'conv_net_2d/conv_2d_1/b/Initializer/zeros' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_1/b' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_1/b/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_1/b/read' type=Identity>, <tf.Operation 'conv_net_2d_1/conv_2d_1/BiasAdd' type=BiasAdd>, <tf.Operation 'conv_net_2d_1/Relu_1' type=Relu>, <tf.Operation 'Reshape/shape' type=Const>, <tf.Operation 'Reshape' type=Reshape>, <tf.Operation 'mlp/linear_0/w/Initializer/truncated_normal/shape' type=Const>, <tf.Operation 'mlp/linear_0/w/Initializer/truncated_normal/mean' type=Const>, <tf.Operation 'mlp/linear_0/w/Initializer/truncated_normal/stddev' type=Const>, <tf.Operation 'mlp/linear_0/w/Initializer/truncated_normal/TruncatedNormal' type=TruncatedNormal>, <tf.Operation 'mlp/linear_0/w/Initializer/truncated_normal/mul' type=Mul>, <tf.Operation 'mlp/linear_0/w/Initializer/truncated_normal' type=Add>, <tf.Operation 'mlp/linear_0/w' type=VariableV2>, <tf.Operation 'mlp/linear_0/w/Assign' type=Assign>, <tf.Operation 'mlp/linear_0/w/read' type=Identity>, <tf.Operation 'mlp_1/linear_0/MatMul' type=MatMul>, <tf.Operation 'mlp/linear_0/b/Initializer/zeros' type=Const>, <tf.Operation 'mlp/linear_0/b' type=VariableV2>, <tf.Operation 'mlp/linear_0/b/Assign' type=Assign>, <tf.Operation 'mlp/linear_0/b/read' type=Identity>, <tf.Operation 'mlp_1/linear_0/add' type=Add>, <tf.Operation 'label' type=Placeholder>, <tf.Operation 'SparseSoftmaxCrossEntropyWithLogits/Shape' type=Shape>, <tf.Operation 'SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' type=SparseSoftmaxCrossEntropyWithLogits>, <tf.Operation 'Const' type=Const>, <tf.Operation 'Mean' type=Mean>, <tf.Operation 'gradients/Shape' type=Const>, <tf.Operation 'gradients/Const' type=Const>, <tf.Operation 'gradients/Fill' type=Fill>, <tf.Operation 'gradients/Mean_grad/Reshape/shape' type=Const>, <tf.Operation 'gradients/Mean_grad/Reshape' type=Reshape>, <tf.Operation 'gradients/Mean_grad/Shape' type=Shape>, <tf.Operation 'gradients/Mean_grad/Tile' type=Tile>, <tf.Operation 'gradients/Mean_grad/Shape_1' type=Shape>, <tf.Operation 'gradients/Mean_grad/Shape_2' type=Const>, <tf.Operation 'gradients/Mean_grad/Const' type=Const>, <tf.Operation 'gradients/Mean_grad/Prod' type=Prod>, <tf.Operation 'gradients/Mean_grad/Const_1' type=Const>, <tf.Operation 'gradients/Mean_grad/Prod_1' type=Prod>, <tf.Operation 'gradients/Mean_grad/Maximum/y' type=Const>, <tf.Operation 'gradients/Mean_grad/Maximum' type=Maximum>, <tf.Operation 'gradients/Mean_grad/floordiv' type=FloorDiv>, <tf.Operation 'gradients/Mean_grad/Cast' type=Cast>, <tf.Operation 'gradients/Mean_grad/truediv' type=RealDiv>, <tf.Operation 'gradients/zeros_like' type=ZerosLike>, <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/PreventGradient' type=PreventGradient>, <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim' type=Const>, <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/ExpandDims' type=ExpandDims>, <tf.Operation 'gradients/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits_grad/mul' type=Mul>, <tf.Operation 'gradients/mlp_1/linear_0/add_grad/Shape' type=Shape>, <tf.Operation 'gradients/mlp_1/linear_0/add_grad/Shape_1' type=Const>, <tf.Operation 'gradients/mlp_1/linear_0/add_grad/BroadcastGradientArgs' type=BroadcastGradientArgs>, <tf.Operation 'gradients/mlp_1/linear_0/add_grad/Sum' type=Sum>, <tf.Operation 'gradients/mlp_1/linear_0/add_grad/Reshape' type=Reshape>, <tf.Operation 'gradients/mlp_1/linear_0/add_grad/Sum_1' type=Sum>, <tf.Operation 'gradients/mlp_1/linear_0/add_grad/Reshape_1' type=Reshape>, <tf.Operation 'gradients/mlp_1/linear_0/add_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'gradients/mlp_1/linear_0/add_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'gradients/mlp_1/linear_0/add_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'gradients/mlp_1/linear_0/MatMul_grad/MatMul' type=MatMul>, <tf.Operation 'gradients/mlp_1/linear_0/MatMul_grad/MatMul_1' type=MatMul>, <tf.Operation 'gradients/mlp_1/linear_0/MatMul_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'gradients/mlp_1/linear_0/MatMul_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'gradients/mlp_1/linear_0/MatMul_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'gradients/Reshape_grad/Shape' type=Shape>, <tf.Operation 'gradients/Reshape_grad/Reshape' type=Reshape>, <tf.Operation 'gradients/conv_net_2d_1/Relu_1_grad/ReluGrad' type=ReluGrad>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_1/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_1/BiasAdd_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_1/BiasAdd_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_1/BiasAdd_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_1/convolution_grad/ShapeN' type=ShapeN>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_1/convolution_grad/Conv2DBackpropInput' type=Conv2DBackpropInput>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_1/convolution_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_1/convolution_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_1/convolution_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_1/convolution_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'gradients/conv_net_2d_1/Relu_grad/ReluGrad' type=ReluGrad>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_0/BiasAdd_grad/BiasAddGrad' type=BiasAddGrad>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_0/BiasAdd_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_0/BiasAdd_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_0/BiasAdd_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_0/convolution_grad/ShapeN' type=ShapeN>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_0/convolution_grad/Conv2DBackpropInput' type=Conv2DBackpropInput>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_0/convolution_grad/Conv2DBackpropFilter' type=Conv2DBackpropFilter>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_0/convolution_grad/tuple/group_deps' type=NoOp>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_0/convolution_grad/tuple/control_dependency' type=Identity>, <tf.Operation 'gradients/conv_net_2d_1/conv_2d_0/convolution_grad/tuple/control_dependency_1' type=Identity>, <tf.Operation 'beta1_power/initial_value' type=Const>, <tf.Operation 'beta1_power' type=VariableV2>, <tf.Operation 'beta1_power/Assign' type=Assign>, <tf.Operation 'beta1_power/read' type=Identity>, <tf.Operation 'beta2_power/initial_value' type=Const>, <tf.Operation 'beta2_power' type=VariableV2>, <tf.Operation 'beta2_power/Assign' type=Assign>, <tf.Operation 'beta2_power/read' type=Identity>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Adam/Initializer/zeros' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Adam' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Adam/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Adam/read' type=Identity>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Adam_1' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Adam_1/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_0/w/Adam_1/read' type=Identity>, <tf.Operation 'conv_net_2d/conv_2d_0/b/Adam/Initializer/zeros' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_0/b/Adam' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_0/b/Adam/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_0/b/Adam/read' type=Identity>, <tf.Operation 'conv_net_2d/conv_2d_0/b/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_0/b/Adam_1' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_0/b/Adam_1/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_0/b/Adam_1/read' type=Identity>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Adam/Initializer/zeros' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Adam' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Adam/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Adam/read' type=Identity>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Adam_1' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Adam_1/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_1/w/Adam_1/read' type=Identity>, <tf.Operation 'conv_net_2d/conv_2d_1/b/Adam/Initializer/zeros' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_1/b/Adam' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_1/b/Adam/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_1/b/Adam/read' type=Identity>, <tf.Operation 'conv_net_2d/conv_2d_1/b/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'conv_net_2d/conv_2d_1/b/Adam_1' type=VariableV2>, <tf.Operation 'conv_net_2d/conv_2d_1/b/Adam_1/Assign' type=Assign>, <tf.Operation 'conv_net_2d/conv_2d_1/b/Adam_1/read' type=Identity>, <tf.Operation 'mlp/linear_0/w/Adam/Initializer/zeros' type=Const>, <tf.Operation 'mlp/linear_0/w/Adam' type=VariableV2>, <tf.Operation 'mlp/linear_0/w/Adam/Assign' type=Assign>, <tf.Operation 'mlp/linear_0/w/Adam/read' type=Identity>, <tf.Operation 'mlp/linear_0/w/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'mlp/linear_0/w/Adam_1' type=VariableV2>, <tf.Operation 'mlp/linear_0/w/Adam_1/Assign' type=Assign>, <tf.Operation 'mlp/linear_0/w/Adam_1/read' type=Identity>, <tf.Operation 'mlp/linear_0/b/Adam/Initializer/zeros' type=Const>, <tf.Operation 'mlp/linear_0/b/Adam' type=VariableV2>, <tf.Operation 'mlp/linear_0/b/Adam/Assign' type=Assign>, <tf.Operation 'mlp/linear_0/b/Adam/read' type=Identity>, <tf.Operation 'mlp/linear_0/b/Adam_1/Initializer/zeros' type=Const>, <tf.Operation 'mlp/linear_0/b/Adam_1' type=VariableV2>, <tf.Operation 'mlp/linear_0/b/Adam_1/Assign' type=Assign>, <tf.Operation 'mlp/linear_0/b/Adam_1/read' type=Identity>, <tf.Operation 'Adam/learning_rate' type=Const>, <tf.Operation 'Adam/beta1' type=Const>, <tf.Operation 'Adam/beta2' type=Const>, <tf.Operation 'Adam/epsilon' type=Const>, <tf.Operation 'Adam/update_conv_net_2d/conv_2d_0/w/ApplyAdam' type=ApplyAdam>, <tf.Operation 'Adam/update_conv_net_2d/conv_2d_0/b/ApplyAdam' type=ApplyAdam>, <tf.Operation 'Adam/update_conv_net_2d/conv_2d_1/w/ApplyAdam' type=ApplyAdam>, <tf.Operation 'Adam/update_conv_net_2d/conv_2d_1/b/ApplyAdam' type=ApplyAdam>, <tf.Operation 'Adam/update_mlp/linear_0/w/ApplyAdam' type=ApplyAdam>, <tf.Operation 'Adam/update_mlp/linear_0/b/ApplyAdam' type=ApplyAdam>, <tf.Operation 'Adam/mul' type=Mul>, <tf.Operation 'Adam/Assign' type=Assign>, <tf.Operation 'Adam/mul_1' type=Mul>, <tf.Operation 'Adam/Assign_1' type=Assign>, <tf.Operation 'Adam' type=NoOp>, <tf.Operation 'ArgMax/dimension' type=Const>, <tf.Operation 'ArgMax' type=ArgMax>, <tf.Operation 'confusion_matrix/Cast_1' type=Cast>, <tf.Operation 'confusion_matrix/assert_non_negative/Const' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/LessEqual' type=LessEqual>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Const' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/All' type=All>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/Const' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/Const_1' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/Const_2' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Switch' type=Switch>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/switch_t' type=Identity>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/switch_f' type=Identity>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/pred_id' type=Identity>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/NoOp' type=NoOp>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/control_dependency' type=Identity>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert/data_0' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert/data_1' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert/data_2' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert/Switch' type=Switch>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert/Switch_1' type=Switch>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Assert' type=Assert>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/control_dependency_1' type=Identity>, <tf.Operation 'confusion_matrix/assert_non_negative/assert_less_equal/Assert/AssertGuard/Merge' type=Merge>, <tf.Operation 'confusion_matrix/control_dependency' type=Identity>, <tf.Operation 'confusion_matrix/assert_non_negative_1/Const' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/LessEqual' type=LessEqual>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Const' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/All' type=All>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/Const' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/Const_1' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/Const_2' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Switch' type=Switch>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/switch_t' type=Identity>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/switch_f' type=Identity>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/pred_id' type=Identity>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/NoOp' type=NoOp>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/control_dependency' type=Identity>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert/data_0' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert/data_1' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert/data_2' type=Const>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert/Switch' type=Switch>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert/Switch_1' type=Switch>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Assert' type=Assert>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/control_dependency_1' type=Identity>, <tf.Operation 'confusion_matrix/assert_non_negative_1/assert_less_equal/Assert/AssertGuard/Merge' type=Merge>, <tf.Operation 'confusion_matrix/control_dependency_1' type=Identity>, <tf.Operation 'confusion_matrix/Cast_2/x' type=Const>, <tf.Operation 'confusion_matrix/Cast_2' type=Cast>, <tf.Operation 'confusion_matrix/assert_less/Less' type=Less>, <tf.Operation 'confusion_matrix/assert_less/Const' type=Const>, <tf.Operation 'confusion_matrix/assert_less/All' type=All>, <tf.Operation 'confusion_matrix/assert_less/Assert/Const' type=Const>, <tf.Operation 'confusion_matrix/assert_less/Assert/Const_1' type=Const>, <tf.Operation 'confusion_matrix/assert_less/Assert/Const_2' type=Const>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/Switch' type=Switch>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/switch_t' type=Identity>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/switch_f' type=Identity>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/pred_id' type=Identity>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/NoOp' type=NoOp>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/control_dependency' type=Identity>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/Assert/data_0' type=Const>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/Assert/data_1' type=Const>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/Assert/data_3' type=Const>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/Assert/Switch' type=Switch>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/Assert/Switch_1' type=Switch>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/Assert/Switch_2' type=Switch>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/Assert' type=Assert>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/control_dependency_1' type=Identity>, <tf.Operation 'confusion_matrix/assert_less/Assert/AssertGuard/Merge' type=Merge>, <tf.Operation 'confusion_matrix/control_dependency_2' type=Identity>, <tf.Operation 'confusion_matrix/assert_less_1/Less' type=Less>, <tf.Operation 'confusion_matrix/assert_less_1/Const' type=Const>, <tf.Operation 'confusion_matrix/assert_less_1/All' type=All>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/Const' type=Const>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/Const_1' type=Const>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/Const_2' type=Const>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/Switch' type=Switch>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/switch_t' type=Identity>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/switch_f' type=Identity>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/pred_id' type=Identity>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/NoOp' type=NoOp>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/control_dependency' type=Identity>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/Assert/data_0' type=Const>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/Assert/data_1' type=Const>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/Assert/data_3' type=Const>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/Assert/Switch' type=Switch>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/Assert/Switch_1' type=Switch>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/Assert/Switch_2' type=Switch>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/Assert' type=Assert>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/control_dependency_1' type=Identity>, <tf.Operation 'confusion_matrix/assert_less_1/Assert/AssertGuard/Merge' type=Merge>, <tf.Operation 'confusion_matrix/control_dependency_3' type=Identity>, <tf.Operation 'confusion_matrix/stack' type=Const>, <tf.Operation 'confusion_matrix/stack_1' type=Pack>, <tf.Operation 'confusion_matrix/transpose/Rank' type=Rank>, <tf.Operation 'confusion_matrix/transpose/sub/y' type=Const>, <tf.Operation 'confusion_matrix/transpose/sub' type=Sub>, <tf.Operation 'confusion_matrix/transpose/Range/start' type=Const>, <tf.Operation 'confusion_matrix/transpose/Range/delta' type=Const>, <tf.Operation 'confusion_matrix/transpose/Range' type=Range>, <tf.Operation 'confusion_matrix/transpose/sub_1' type=Sub>, <tf.Operation 'confusion_matrix/transpose' type=Transpose>, <tf.Operation 'confusion_matrix/ones_like/Shape' type=Shape>, <tf.Operation 'confusion_matrix/ones_like/Const' type=Const>, <tf.Operation 'confusion_matrix/ones_like' type=Fill>, <tf.Operation 'confusion_matrix/ToInt64' type=Cast>, <tf.Operation 'confusion_matrix/zeros/Const' type=Const>, <tf.Operation 'confusion_matrix/zeros' type=Fill>, <tf.Operation 'confusion_matrix/SparseTensorDenseAdd' type=SparseTensorDenseAdd>, <tf.Operation 'save/Const' type=Const>, <tf.Operation 'save/SaveV2/tensor_names' type=Const>, <tf.Operation 'save/SaveV2/shape_and_slices' type=Const>, <tf.Operation 'save/SaveV2' type=SaveV2>, <tf.Operation 'save/control_dependency' type=Identity>, <tf.Operation 'save/RestoreV2/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2' type=RestoreV2>, <tf.Operation 'save/Assign' type=Assign>, <tf.Operation 'save/RestoreV2_1/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_1/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_1' type=RestoreV2>, <tf.Operation 'save/Assign_1' type=Assign>, <tf.Operation 'save/RestoreV2_2/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_2/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_2' type=RestoreV2>, <tf.Operation 'save/Assign_2' type=Assign>, <tf.Operation 'save/RestoreV2_3/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_3/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_3' type=RestoreV2>, <tf.Operation 'save/Assign_3' type=Assign>, <tf.Operation 'save/RestoreV2_4/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_4/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_4' type=RestoreV2>, <tf.Operation 'save/Assign_4' type=Assign>, <tf.Operation 'save/RestoreV2_5/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_5/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_5' type=RestoreV2>, <tf.Operation 'save/Assign_5' type=Assign>, <tf.Operation 'save/RestoreV2_6/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_6/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_6' type=RestoreV2>, <tf.Operation 'save/Assign_6' type=Assign>, <tf.Operation 'save/RestoreV2_7/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_7/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_7' type=RestoreV2>, <tf.Operation 'save/Assign_7' type=Assign>, <tf.Operation 'save/RestoreV2_8/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_8/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_8' type=RestoreV2>, <tf.Operation 'save/Assign_8' type=Assign>, <tf.Operation 'save/RestoreV2_9/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_9/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_9' type=RestoreV2>, <tf.Operation 'save/Assign_9' type=Assign>, <tf.Operation 'save/RestoreV2_10/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_10/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_10' type=RestoreV2>, <tf.Operation 'save/Assign_10' type=Assign>, <tf.Operation 'save/RestoreV2_11/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_11/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_11' type=RestoreV2>, <tf.Operation 'save/Assign_11' type=Assign>, <tf.Operation 'save/RestoreV2_12/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_12/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_12' type=RestoreV2>, <tf.Operation 'save/Assign_12' type=Assign>, <tf.Operation 'save/RestoreV2_13/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_13/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_13' type=RestoreV2>, <tf.Operation 'save/Assign_13' type=Assign>, <tf.Operation 'save/RestoreV2_14/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_14/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_14' type=RestoreV2>, <tf.Operation 'save/Assign_14' type=Assign>, <tf.Operation 'save/RestoreV2_15/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_15/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_15' type=RestoreV2>, <tf.Operation 'save/Assign_15' type=Assign>, <tf.Operation 'save/RestoreV2_16/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_16/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_16' type=RestoreV2>, <tf.Operation 'save/Assign_16' type=Assign>, <tf.Operation 'save/RestoreV2_17/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_17/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_17' type=RestoreV2>, <tf.Operation 'save/Assign_17' type=Assign>, <tf.Operation 'save/RestoreV2_18/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_18/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_18' type=RestoreV2>, <tf.Operation 'save/Assign_18' type=Assign>, <tf.Operation 'save/RestoreV2_19/tensor_names' type=Const>, <tf.Operation 'save/RestoreV2_19/shape_and_slices' type=Const>, <tf.Operation 'save/RestoreV2_19' type=RestoreV2>, <tf.Operation 'save/Assign_19' type=Assign>, <tf.Operation 'save/restore_all' type=NoOp>, <tf.Operation 'init' type=NoOp>]\n"
     ]
    }
   ],
   "source": [
    "# This is the pretrained model\n",
    "session = tf.Session()\n",
    "\n",
    "# Load graph and all variables into memory\n",
    "saver = tf.train.import_meta_graph(cifar_dir + 'cifar10_network.meta')\n",
    "saver.restore(session, cifar_dir + 'cifar10_network')\n",
    "\n",
    "# Print out the operations of the graph\n",
    "print(session.graph.get_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a huge list of operations, but it looks like the operations of interest are `<tf.Operation 'input_placeholder' type=Placeholder>`, `<tf.Operation 'conv_net_2d_1/Relu' type=Relu>`, and `<tf.Operation 'mlp_1/linear_0/add' type=Add>`. The moral of this story is that you should always name your tensors consistently and document your networks clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0 520   0  28   0   2   0  90 310  49]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0 499   0   5   0   3   0 143 145 205]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# This is the output of the convolutional stack <tf.Operation 'conv_net_2d_1/Relu' type=Relu>\n",
    "\n",
    "graph = session.graph\n",
    "x = graph.get_tensor_by_name('input_placeholder:0')\n",
    "conv_out = graph.get_tensor_by_name('conv_net_2d_1/Relu:0')\n",
    "mlp_out = graph.get_tensor_by_name('mlp_1/linear_0/add:0')\n",
    "\n",
    "y = tf.placeholder(tf.int32, shape=[None])\n",
    "conf_matrix_op = tf.confusion_matrix(y, tf.argmax(mlp_out, axis=1), num_classes=10)\n",
    "conf_matrix = session.run(conf_matrix_op, {x: subset_test_data, y: np.squeeze(subset_test_labels)})\n",
    "\n",
    "# This is confusion matrix on pretrained model\n",
    "# Actually, nothing is classified correctly\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This network doesn't classify any of our data correctly. So we're going to replace the classifying dense layer and train it on our data. We'll make sure that the weights in the convolutional stack don't change with [tf.stop_gradient](https://www.tensorflow.org/api_docs/python/tf/stop_gradient). This operation is a special version of the identity that copies data in the forward pass, but stops gradients in the backward pass. This allows the later parts of the network to update while preserving everything preceding, up to the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0930 16:43:51.024467 47074515312768 deprecation.py:323] From <ipython-input-6-3d292f696282>:7: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0930 16:43:51.040288 47074515312768 deprecation.py:506] From /util/opt/anaconda/deployed-conda-envs/packages/tensorflow/envs/tensorflow-1.14.0-py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "# As we don't have much training data we train a much smaller network\n",
    "\n",
    "# This allows forward pass through it, but does not allow gradients to flow through it\n",
    "# It acts as a block so training does not continue through it\n",
    "# We thus only update parameters before this\n",
    "conv_out_no_gradient = tf.reshape(tf.stop_gradient(conv_out), [-1, 16*16*32]) # flatten input from 16x16x32\n",
    "our_dense_layer = tf.layers.dense(conv_out_no_gradient, 2, name=\"our_dense_layer\")\n",
    "\n",
    "# Operation to create confusion matrix\n",
    "conf_matrix_op = tf.confusion_matrix(y, tf.argmax(our_dense_layer, axis=1), num_classes=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also use [tf.get_collection](https://www.tensorflow.org/api_docs/python/tf/get_collection) to get the variables we've added for initialization. We want to make sure not to run the global variable initializer, because that would reset the variables from the values loaded from the saved model, so we'll use [tf.variables_initializer](https://www.tensorflow.org/api_docs/python/tf/variables_initializer) to only initialize the subset we've added. `tf.get_collection` uses [GraphKeys](https://www.tensorflow.org/api_docs/python/tf/GraphKeys) to get subsets of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# change data to be a binary classification probem between airplanes and birds (0 and 1)\n",
    "subset_train_labels[subset_train_labels > 0] = 1\n",
    "subset_test_labels[subset_test_labels > 0] = 1\n",
    "\n",
    "with tf.name_scope('optimizer') as scope:\n",
    "    # define new loss\n",
    "    # Sparse softmax is often used when you have only two classes (one-hot encoding not needed)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=our_dense_layer)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = optimizer.minimize(cross_entropy)\n",
    "\n",
    "# initialize new variables (without declaring all as new variables globally)\n",
    "# Declaring all as new is what we have done before\n",
    "# These 3 are the layers we have created above\n",
    "optimizer_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"optimizer\")\n",
    "dense_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"our_dense_layer\")\n",
    "\n",
    "# We would use the name given here is we were planning to save and reload it\n",
    "session.run(tf.variables_initializer(optimizer_vars + dense_vars, name='init'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we'll train for one epoch and and evaluate like we usually do to see the effect of our transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BINARY CONFUSION MATRIX:\n",
      "[[586 413]\n",
      " [ 61 939]]\n"
     ]
    }
   ],
   "source": [
    "# train for an epoch using this modified network with the block\n",
    "\n",
    "batch_size = 16\n",
    "for i in range(subset_train_data.shape[0] // batch_size):\n",
    "    batch_xs = subset_train_data[i*batch_size:(i+1)*batch_size, :]\n",
    "    batch_ys = np.squeeze(subset_train_labels[i*batch_size:(i+1)*batch_size])\n",
    "    session.run(train_op, {x: batch_xs, y: batch_ys})\n",
    "\n",
    "# and evaluate\n",
    "# Note this now has only two possible outputs as we only consider two classes\n",
    "conf_matrix = session.run(conf_matrix_op, {x: subset_test_data, y: np.squeeze(subset_test_labels)})\n",
    "print('BINARY CONFUSION MATRIX:')\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad for such a difficult classification problem and small dataset. Notice that we go from a 10 class problem to a 2 class one. The output can be totally different from the original, but transfer learning is most useful when in the same modality (RGB vs. greyscale or natural images vs. audio, etc.)\n",
    "\n",
    "Another option, instead of using tf.stop_gradient, is to pass an explicit list of trainable variables to [minimize](https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer#minimize). Normally, the `var_list` argument is set to all the variables under `GraphKeys.TRAINABLE_VARIABLES`, but we can set it just to be the variables we've added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instead of using stop_gradient (in case there are multiple paths back)\n",
    "# We can instead pass in list of variables, and it only updates those declared variables\n",
    "\n",
    "# this only trains a few variables by only updating the collection of variables\n",
    "train_op = optimizer.minimize(cross_entropy, var_list=tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"our_dense_layer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add an [l2 regularizer](https://www.tensorflow.org/api_docs/python/tf/nn/l2_loss) to the weight matrix of the old dense layer `<tf.Operation 'mlp/linear_0/w' type=VariableV2>`, then get a train_op with `AdamOptimizer.minimize` that trains that layer (`linear_0`), with the new regularizer on the cross entropy loss of its output with the correct label.\n",
    "\n",
    "Hints:\n",
    "\n",
    "1. Remember that 'mlp/linear_0/w' is the name of an Operation, not a Tensor\n",
    "2. We retrieved the output of the layer above as `mlp_out`\n",
    "3. No code needs to run, it just needs to be correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Start the session\n",
    "session = tf.Session()\n",
    "\n",
    "# Load graph and all variables into memory\n",
    "saver = tf.train.import_meta_graph(cifar_dir + 'cifar10_network.meta')\n",
    "saver.restore(session, cifar_dir + 'cifar10_network')\n",
    "\n",
    "# Grab tensorflow graph from session\n",
    "graph = session.graph\n",
    "\n",
    "# Identify the input_placeholder tensor for initializing new graph\n",
    "x = graph.get_tensor_by_name('input_placeholder:0')\n",
    "# Define placeholder for output predictions\n",
    "y = tf.placeholder(tf.int32, shape=[None])\n",
    "\n",
    "# Grab the tensor that, in the original graph, feeds directly into the mpl/linear_0 layer\n",
    "conv_out = graph.get_tensor_by_name('conv_net_2d_1/Relu:0')\n",
    "# Flatten it for feeding into dense layers and stop gradients from flowing back into the convolutional layer\n",
    "conv_out_no_gradient = tf.reshape(tf.stop_gradient(conv_out), [-1, 16*16*32]) # flatten input from 16x16x32\n",
    "\n",
    "# Here we define a dense layer which the above-defined tensor flows into\n",
    "# We reuse the weights from the mlp/linear_0 layer, while adding L2 regularization\n",
    "# This allows us to keep what was previously learned from the original graph, while incorporating in the new graph\n",
    "# in such a way it can be modified and still learned from\n",
    "# NOTE: HCC was down when developing this, and are not 100% sure we grabbed the correct name for the weights\n",
    "modified_old_dense_layer = tf.layers.dense(conv_out_no_gradient, 10, activation=tf.nn.relu,\n",
    "                                   kernel_regularizer=tf.contrib.layers.l2_regularizer(scale=0.001),\n",
    "                                   bias_regularizer=tf.contrib.layers.l2_regularizer(scale=0.001),name='mlp/linear_0/w',\\\n",
    "                                   reuse=True)\n",
    "\n",
    "# This defines the layer to take us from the above 10-neuron output to our desired 2 classes\n",
    "our_dense_layer = tf.layers.dense(modified_old_dense_layer, 2, activation=tf.nn.relu,name='our_dense_layer')\n",
    "\n",
    "\n",
    "############### This code is very similar to that used previously in notebook ##################\n",
    "# If above defined correctly this shoudl work\n",
    "\n",
    "# Operation to create confusion matrix\n",
    "conf_matrix_op = tf.confusion_matrix(y, tf.argmax(our_dense_layer, axis=1), num_classes=2)\n",
    "\n",
    "# Change data to be a binary classification probem between airplanes and birds (0 and 1)\n",
    "subset_train_labels[subset_train_labels > 0] = 1\n",
    "subset_test_labels[subset_test_labels > 0] = 1\n",
    "\n",
    "# Define optimizer we will use for training\n",
    "with tf.name_scope('optimizer') as scope:\n",
    "    # Define new loss\n",
    "    regularization_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    # this is the weight of the regularization part of the final loss\n",
    "    REG_COEFF = 0.1 \n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=our_dense_layer)\n",
    "    xentropy_w_reg = cross_entropy + REG_COEFF * sum(regularization_losses)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    train_op = optimizer.minimize(xentropy_w_reg)\n",
    "\n",
    "# Initialize new variables below (without declaring all as new variables globally)\n",
    "# Used for optimizer\n",
    "optimizer_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"optimizer\")\n",
    "# Used for modified 10 neuron layer\n",
    "modified_old_dense_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"modified_old_dense_layer\")\n",
    "# Used for output dense layer\n",
    "dense_vars = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, \"our_dense_layer\")\n",
    "\n",
    "# Initialize these variables\n",
    "session.run(tf.variables_initializer(optimizer_vars + modified_old_dense_vars + dense_vars, name='init'))\n",
    "\n",
    "# train modified network for 1 epoch\n",
    "batch_size = 16\n",
    "for i in range(subset_train_data.shape[0] // batch_size):\n",
    "    batch_xs = subset_train_data[i*batch_size:(i+1)*batch_size, :]\n",
    "    batch_ys = np.squeeze(subset_train_labels[i*batch_size:(i+1)*batch_size])\n",
    "    session.run(train_op, {x: batch_xs, y: batch_ys})\n",
    "\n",
    "# Evaluate using a confusion matrix\n",
    "conf_matrix = session.run(conf_matrix_op, {x: subset_test_data, y: np.squeeze(subset_test_labels)})\n",
    "print('BINARY CONFUSION MATRIX:')\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Normalization\n",
    "\n",
    "We're going to briefly cover how to use batch norm; see Chapter 11 of textbook for more info on batch normalization. It's used to deal with internal covariate shift, or the tendency of the mean activation of a layer over the dataset to drift away from 0. Keeping this close to zero has an effect similar to normalization of the data in terms of making the learning problem easier and less sensitive to initial conditions. Generally normalization occurs just before the activation of a layer.\n",
    "\n",
    "TensorFlow implements batch norm with [tf.layers.batch_normalization](https://www.tensorflow.org/api_docs/python/tf/nn/batch_normalization). It only requires the input tensor, but may be customized with many, many optimal parameters. It's important to set whether the network is training or not with the `training` argument because, to quote the TensorFlow docs:\n",
    "\n",
    "> training: Either a Python boolean, or a TensorFlow boolean scalar tensor (e.g. a placeholder). Whether to return the output in training mode (normalized with statistics of the current batch) or in inference mode (normalized with moving statistics). NOTE: make sure to set this parameter correctly, or else your training/inference will not work properly.\n",
    "\n",
    "Batch normalization maintains internal statistics (its own parameters) on how to normalize between minibatches. It's important that these are updated as training proceeds, but equally important that they're not updated when the network layers aren't being updated as well.\n",
    "\n",
    "In order to ensure the parameters get updated in the correct order, dependencies should be explicitly signaled. By default the update ops are placed in tf.GraphKeys.UPDATE_OPS, so they need to be added as a dependency to the train_op. For example:\n",
    "\n",
    "```\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_op = optimizer.minimize(loss)\n",
    "```\n",
    "\n",
    "The `axis` argument should be set if channels isn't the last dimension of your imagetensors.\n",
    "\n",
    "An example use in a convolutional block, also using the [tf.nn.elu](https://www.tensorflow.org/api_docs/python/tf/nn/elu) activation (closely related to ReLU):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0930 17:00:51.914386 47074515312768 deprecation.py:323] From <ipython-input-11-b2e1cf1aef23>:13: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0930 17:00:52.609322 47074515312768 deprecation.py:323] From <ipython-input-11-b2e1cf1aef23>:14: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n"
     ]
    }
   ],
   "source": [
    "# We have to give it input tensor and whether we want to train it when using batch normalization\n",
    "# control dependencies makes sure that everything has completed before this line before running next line\n",
    "# Tensorflow tends to reorder operations for speed of computation unless told not to\n",
    "\n",
    "tf.reset_default_graph()\n",
    "def my_conv_block(inputs, filters, is_training):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        - inputs: 4D tensor of shape NHWC\n",
    "        - filters: iterable of ints\n",
    "    \"\"\"\n",
    "    with tf.name_scope('conv_block') as scope:\n",
    "        x = inputs\n",
    "        for i in range(len(filters)):\n",
    "            x = tf.layers.conv2d(x, filters[0], 3, 1, padding='same')\n",
    "            \n",
    "            # Batch Normalization generally put after layer and before activation function\n",
    "            x = tf.layers.batch_normalization(x, training=is_training)\n",
    "            \n",
    "            x = tf.nn.elu(x)\n",
    "    return x\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 32, 32, 3])\n",
    "conv_output = my_conv_block(x, [16, 32, 64], True)\n",
    "flat_conv = tf.reshape(conv_output, [-1, 32*32*64])\n",
    "output = tf.layers.dense(flat_conv, 10)\n",
    "\n",
    "y = tf.placeholder(tf.int32, [None])\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=output)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_op = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
